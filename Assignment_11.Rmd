
---
title: "Assignment 11"
author: "Kaitlyn Fales"
date: "10/7/2020"
output: html_document
---



```{r setup, include=FALSE}
knitr::opts_chunk$set(message = FALSE)
```


-------

1. Install the package `mlbench` and use the follows to import the data

```{r}
library(mlbench)
library(tidyverse)
data(PimaIndiansDiabetes)
df <- PimaIndiansDiabetes
df <- df %>% 
  rename(target = diabetes)
```

- Set seed to be 2020. 
```{r}
set.seed(2020)
```

- Partition the data into 80% training and 20% testing.  
```{r}
library(caret)
splitIndex <- createDataPartition(df$target, p = .80, 
                                  list = FALSE)
df_train <- df[ splitIndex,]
df_test <- df[-splitIndex,]
```

-------

2. Use cross-validation with 10 k-folds to find the maxdepth with the greatest accuracy. Plot the accuracy associated with different maxdepths against the maxdepths. The range to search for maxdepth is from 1 to 10. 
```{r}
tuneGrid_cv <-  expand.grid(maxdepth = 1:10)
trControl_cv <-  trainControl(method = "cv", number = 10)
tree_cv <- train(target~., data=df_train, method = "rpart2", 
                 trControl = trControl_cv, tuneGrid = tuneGrid_cv)
plot(tree_cv)
print(tree_cv)
```

-------

3. Make the final decision to select the maxdepth for your decision tree.  Is your selected maxdepth the same as the maxdepth found in 2. 
```{r}
# I will be selecting the tree with a max depth of 1, which is the same as the model that caret selected because it is the simplest and also has the highest accuracy.
```

-------

4. Calculate the accuracy of your decision tree (the decision tree with your selected maxdepth in 3) on the test data. 

```{r}
# Max Depth of 1
pred_cv <- predict(tree_cv, df_test)
cm_cv <- confusionMatrix(data = pred_cv, reference = df_test$target, positive = "pos")
cm_cv$overall[1]
```


-------

5. Redo 2-4 with an alternative method to cross-validation. 
```{r}
# Approach 2
tuneGrid = expand.grid(maxdepth = 1:10)
trControl = trainControl(method = "LGOCV",
                         number = 10)
tree_approach2 <- train(target~., data=df_train, 
                                method = "rpart2", 
                                trControl = trControl,
                                tuneGrid = tuneGrid)
plot(tree_approach2)
print(tree_approach2)
```

```{r}
# I am choosing the model with a max depth of 7 because it is simpler than the model with a max depth of 8, and the accuracy is nearly identical.

# Max Depth of 7
library(rpart)
tree_model <- rpart(target ~ ., data = df_train,
                 control = rpart.control(maxdepth = 7))
pred <- predict(tree_model, df_test)
pred <- predict(tree_model, df_test, type = "class")
cm <- confusionMatrix(data = pred,reference = df_test$target,positive =   "pos")
cm$overall[1]
```
```{r}
# The best model is a tree with a max depth of 7.
```

